Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Trajectory analysis of _C. elegans_ tracks collected in our lab setup\nThis project contains code that allows us to analyze tracking from our experimental setup, that consists in looking at\n_C. elegans_ foraging behavior in various landscapes. It is specifically designed for our setup and data format.\n\n## Requirements\nI am running the code in both Windows 10 and Ubuntu 20.04.  \nI am using Python 3.8, and the following libraries are installed:  \nDateTime 4.7  \t\nPillow\t9.2.0  \ncontourpy\t1.0.5  \ncycler\t0.11.0  \nfonttools\t4.37.4  \nimportlib-metadata\t5.0.0  \nkiwisolver\t1.4.4  \nllvmlite\t0.39.1  \nmatplotlib\t3.6.1  \nnumba\t0.56.4  \nnumpy\t1.23.3  \npackaging\t21.3  \npandas\t1.5.0  \npip\t21.3.1  \npyparsing\t3.0.9  \npython-dateutil\t2.8.2  \npytz\t2022.2.1  \nscipy\t1.9.1  \nsetuptools\t60.2.0  \nsix\t1.16.0  \nwheel\t0.37.1  \nzipp\t3.10.0  \nzope.interface\t5.4.0  \n\n## Project structure\n### param.py\nContains global parameters, for easier editing.\n\n### find_data.py\nContains the auxiliary functions related to finding the data in a specific path, and reformatting it to dataframes.  \nThe output data should be a pandas dataframe, containing tracking ID, trajectory, and folder name.  \nTrajectories are in the following format: [[x0, x1, ..., xN], [y0, y1, ..., yN]] (xi and yi being respectively the x and y coordinates \nof the individual at time i).  \nAlso contains a function that takes a folder name, and returns \"metadata\" found in that folder:\ncondition number, patch positions, patch densities. This allows to not have this info copied in every line of the data\ntable, which would make it uselessly large.\n\n### generate_results.py\nThis contains trajectory analysis functions (compute number of visited patches, stuff like that). Contains the generate_and_save\nfunction, that will:\n- Extract and save the trajectories in \"trajectories.csv\"\n- Run analyses on these trajectories, and save the results in a table in the original path inputted by the user, named \"results.csv\".\n\n### main.py \nContains functions to:\n- derive statistics from the results returned by generate_results.py\n- plot these statistics using mostly badly written functions\n\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
--- a/README.md	
+++ b/README.md	
@@ -2,6 +2,10 @@
 This project contains code that allows us to analyze tracking from our experimental setup, that consists in looking at
 _C. elegans_ foraging behavior in various landscapes. It is specifically designed for our setup and data format.
 
+## Disclaimer
+This is an old version of our code that I kept for reproducibility purposes (since our results changed when I switched
+to the new data structure, I want to figure out if something is wrong here or there).
+
 ## Requirements
 I am running the code in both Windows 10 and Ubuntu 20.04.  
 I am using Python 3.8, and the following libraries are installed:  
Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># This is a sample Python script.\n\n# Press Shift+F10 to execute it or replace it with your code.\n# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import bootstrap\nimport random\n\n# My code\nimport generate_results as gr\nimport find_data as fd\nfrom param import *\nimport json\n\ndef results_per_condition(result_table, column_name, divided_by = \"\"):\n    \"\"\"\n    Function that takes our result table and a column name (as a string)\n    Returns the list of values of that column pooled by condition, a list of the average value for each condition, and a\n    bootstrap confidence interval for each value.\n    Can take in a third argument, column name by which you want to divide the main column, plate by plate\n    eg: divide duration sum by nb of visits for each plate to get average visit duration for each plate\n    \"\"\"\n\n    # Initializing a list\n    list_of_conditions = np.unique(result_table[\"condition\"])\n    list_of_plates = np.unique(result_table[\"folder\"])\n\n    # Full list\n    full_list_of_values = [list(i) for i in np.zeros((len(list_of_conditions), 1), dtype='int')]\n\n    # List of average\n    list_of_avg_values = np.zeros(len(list_of_conditions))\n\n    # Initializing errors\n    errors_inf = np.zeros(len(list_of_conditions))\n    errors_sup = np.zeros(len(list_of_conditions))\n\n    for i_condition in range(len(list_of_conditions)):\n        # Extracting and slicing\n        current_condition = list_of_conditions[i_condition]\n        current_data = result_table[result_table[\"condition\"] == current_condition]\n        list_of_plates = np.unique(current_data[\"folder\"])\n\n        # Compute average for each plate of the current condition, save it in a list\n        list_of_values = np.zeros(len(list_of_plates))\n\n        for i_plate in range(len(list_of_plates)):\n            # Take only one plate\n            current_plate = current_data[current_data[\"folder\"] == list_of_plates[i_plate]]\n            if divided_by != \"\": # In this case, we want to divide column name by another one\n                if np.sum(current_plate[divided_by]) != 0: # Non zero check for division\n                    list_of_values[i_plate] = np.sum(current_plate[column_name]) / np.sum(current_plate[divided_by])\n                else:\n                    print(\"Trying to divide by 0... what a shame\")\n            else: # No division has to be made\n                if column_name == \"proportion_of_visited_patches\" or column_name == \"nb_of_visited_patches\": # Special case: divide by total nb of patches in plate\n                    current_plate = current_plate.reset_index()\n                    list_of_visited_patches = [json.loads(current_plate[\"list_of_visited_patches\"][i]) for i in range(len(current_plate[\"list_of_visited_patches\"]))]\n                    list_of_visited_patches = [i for liste in list_of_visited_patches for i in liste]\n                    if column_name == \"nb_of_visited_patches\":\n                        list_of_values[i_plate] = len(np.unique(list_of_visited_patches))\n                    else:\n                        list_total_patch = [52, 24, 7, 25, 52, 24, 7, 25, 24, 24, 24, 24]\n                        list_of_values[i_plate] = len(np.unique(list_of_visited_patches))\\\n                                              /list_total_patch[i_condition]\n                if column_name == \"furthest_patch_distance\":\n                    list_of_values[i_plate] = np.max(current_plate[column_name])\n                else:\n                    list_of_values[i_plate] = np.sum(current_plate[column_name])\n\n        # Keep in memory the full list of averages\n        full_list_of_values[i_condition] = list_of_values\n\n        # Average for the current condition\n        list_of_avg_values[i_condition] = np.mean(list_of_values)\n\n        # Bootstrapping on the plate avg duration\n        bootstrap_ci = bottestrop_ci(list_of_values, 100)\n        errors_inf[i_condition] = list_of_avg_values[i_condition] - bootstrap_ci[0]\n        errors_sup[i_condition] = bootstrap_ci[1] - list_of_avg_values[i_condition]\n\n    return list_of_conditions, full_list_of_values, list_of_avg_values, [errors_inf, errors_sup]\n\ndef bottestrop_ci(data, nb_resample):\n    '''\n    Function that takes a dataset and returns a confidence interval using nb_resample samples for bootstrapping\n    '''\n    bootstrapped_means = []\n    #data = [x for x in data if str(x) != 'nan']\n    for i in range(nb_resample):\n        y = []\n        for k in range(len(data)):\n            y.append(random.choice(data))\n        avg = np.mean(y)\n        bootstrapped_means.append(avg)\n    bootstrapped_means.sort()\n    return [np.percentile(bootstrapped_means, 5), np.percentile(bootstrapped_means, 95)]\n\ndef traj_draw(data, i_condition, n_max = 4, plot_patches = False):\n    \"\"\"\n    Function that takes in our dataframe format, using columns: \"x\", \"y\", \"id_conservative\", \"folder\"\n    and extracting \"condition\" info in metadata\n    Extracts list of series of positions from indicated condition and draws them, with one color per id\n    :param data: dataframe containing the series of (x,y) positions ([[x0,x1,x2...] [y0,y1,y2...])\n    :return: trajectory plot\n    \"\"\"\n    worm_list = np.unique(data[\"id_conservative\"])\n    nb_of_worms = len(worm_list)\n    colors = plt.cm.jet(np.linspace(0, 1, nb_of_worms))\n    previous_folder = 0\n    n_plate = 1\n    for i_worm in range(nb_of_worms):\n        current_worm = worm_list[i_worm]\n        current_list_x = data[data[\"id_conservative\"] == current_worm][\"x\"]\n        current_list_y = data[data[\"id_conservative\"] == current_worm][\"y\"]\n        current_folder = list(data[\"folder\"][data[\"id_conservative\"] == worm_list[i_worm]])[0]\n        metadata = fd.folder_to_metadata(current_folder)\n        current_condition = metadata[\"condition\"][0]\n        plt.suptitle(\"Trajectories for condition \" + str(i_condition))\n        if current_condition == i_condition:\n            if previous_folder != current_folder or previous_folder == 0:  # if we just changed plate or if it's the 1st\n                if n_plate > n_max:\n                    plt.show()\n                    n_plate = 1\n                plt.subplot(n_max//2, n_max//2, n_plate)\n                n_plate += 1\n                # if previous_folder != 0: #if its not the first (if its the first theres nothing to show)\n                # plt.show()\n                # Show background and patches\n                previous_folder = current_folder\n                patches = metadata[\"patch_centers\"]\n                patch_densities = metadata[\"patch_densities\"]\n                # composite = plt.imread(current_folder[:-len(\"traj.csv\")] + \"composite_patches.tif\")\n                background = plt.imread(current_folder[:-len(\"traj.csv\")] + \"background.tif\")\n                fig = plt.gcf()\n                ax = fig.gca()\n                fig.set_tight_layout(True)\n                # ax.imshow(composite)\n                ax.imshow(background, cmap='gray')\n                for i_patch in range(len(patches)):\n                    circle = plt.Circle((patches[i_patch][0], patches[i_patch][1]), 40, color=\"grey\",\n                                        alpha=min(1, patch_densities[i_patch][0]))\n                    fig = plt.gcf()\n                    ax = fig.gca()\n                    if plot_patches:\n                        ax.add_patch(circle)\n            # Plot worm trajectory\n            plt.plot(current_list_x, current_list_y, color=colors[i_worm])\n    plt.show()\n    # for i_traj in range(len(trajectories)):\n    #     reformatted_trajectory = list(zip(*trajectories[i_traj])) # converting from [x y][x y][x y] format to [x x x] [y y y]\n    #     plt.plot(reformatted_trajectory[0],reformatted_trajectory[1])\n\ndef check_patches(folder_list):\n    \"\"\"\n    Function that takes a folder list, and for each folder, will:\n    plot the patch positions on the composite patch image, to check if our metadata matches our actual data\n    \"\"\"\n    for folder in folder_list:\n        metadata = fd.folder_to_metadata(folder)\n        patches = metadata[\"patch_centers\"]\n\n        lentoremove = len('traj.csv')  # removes traj from the current path, to get to the parent folder\n        folder = folder[:-lentoremove]\n\n        background = plt.imread(folder + \"background.tif\")\n        composite = plt.imread(folder + \"composite_patches.tif\")\n\n        fig, ax = plt.subplots()\n        background = ax.imshow(background, cmap = 'gray')\n        # composite = ax.imshow(composite)\n\n        patches = metadata[\"patch_centers\"]\n        patch_densities = metadata[\"patch_densities\"]\n        for i_patch in range(len(patches)):\n            circle = plt.Circle((patches[i_patch][0], patches[i_patch][1]), 50, color=\"white\", alpha=0.5)\n            fig = plt.gcf()\n            ax = fig.gca()\n            ax.add_patch(circle)\n\n        plt.title(folder)\n\n        plt.show()\n\ndef plot_selected_data(plot_title, condition_low, condition_high, column_name, condition_names, divided_by = \"\", mycolor = \"blue\"):\n    \"\"\"\n    This function will plot a selected part of the data. Selection is described as follows:\n    - condition_low, condition_high: bounds on the conditions (0,3 => function will plot conditions 0, 1, 2, 3)\n    - column_name:\n    \"\"\"\n    # Getting results\n    list_of_conditions, list_of_avg_each_plate, average_per_condition, errorbars = results_per_condition(results, column_name, divided_by)\n\n    # Slicing to get condition we're interested in\n    list_of_conditions = list_of_conditions[condition_low:condition_high+1]\n    list_of_avg_each_plate = list_of_avg_each_plate[condition_low:condition_high+1]\n    average_per_condition = average_per_condition[condition_low:condition_high+1]\n    errorbars[0] = errorbars[0][condition_low:condition_high+1]\n    errorbars[1] = errorbars[1][condition_low:condition_high+1]\n\n    # Plotttt\n    plt.title(plot_title)\n    fig = plt.gcf()\n    ax = fig.gca()\n    # Plot condition averages as a bar plot\n    ax.bar(list_of_conditions, average_per_condition, color = mycolor)\n    ax.set_xticks(range(len(list_of_conditions)))\n    ax.set_xticklabels(condition_names)\n    ax.errorbar(list_of_conditions, average_per_condition, errorbars, fmt='.k', capsize=5)\n    ax.set(xlabel=\"Condition number\")\n    # Plot plate averages as scatter on top\n    for i in range(len(list_of_conditions)):\n        ax.scatter([list_of_conditions[i] for j in range(len(list_of_avg_each_plate[i]))], list_of_avg_each_plate[i], color=\"red\")\n    plt.show()\n\n# I have two lines, one for Windows and the other for Linux:\nif fd.is_linux():\n    path = \"/home/admin/Desktop/Camera_setup_analysis/Results_minipatches_20221108_clean/\"\nelse:\n    path = \"C:/Users/Asmar/Desktop/Thèse/2022_summer_videos/Results_minipatches_Nov2022_clean/\"\n\n# Extracting data, the function looks for all \"traj.csv\" files in the indicated path (will look into subfolders)\n# It will then generate a \"results\" table, with one line per worm, and these info:\n# NOTE: lists are stored as strings in the csv so we retrieve the values with json loads function\n#         results_table[\"folder\"] = folder from which the worm comes (so plate identifier)\n#         results_table[\"condition\"] = condition written on the plate of the worm\n#         results_table[\"worm_id\"] = number of the worm (100 times the file number + id attributed by tracking algorithm)\n#         results_table[\"total_time\"] = total number of frames for this worm\n#         results_table[\"raw_visits\"] = list outputed by patch_visits_single_traj (see its description)\n#         results_table[\"order_of_visits\"] = list of order of visits [2 3 0 1] = first patch 2, then patch 3, etc\n#         results_table[\"duration_sum\"] = total duration of visits for each worm\n#         results_table[\"nb_of_visits\"] = nb of visits to patches this worm did\n#         results_table[\"nb_of_visited_patches\"] = nb of different patches it visited\n#         results_table[\"furthest_patch_distance\"] = furthest patch visited\n#         results_table[\"total_transit_time\"] = total time spent outside of patches (same as total_time - duration_sum)\n#         results_table[\"adjusted_raw_visits\"] = adjusted: consecutive visits to the same patch are counted as one\n#         results_table[\"adjusted_duration_sum\"] = should be the same as duration sum (did this to check)\n#         results_table[\"adjusted_nb_of_visits\"] = nb of adjusted visits\n\n# Only run this once in the beginning of your analysis!\n### Saves these results in a \"results.csv\" file in path, so no need to run this line every time!\nregenerate_data = False # Set to True to regenerate the dataset, otherwise use the saved one\nif regenerate_data:\n    gr.generate_and_save(path)  # run this once, will save results under path+\"results.csv\"\n\n# Retrieve results from what generate_and_save has saved\ntrajectories = pd.read_csv(path + \"trajectories.csv\")\nresults = pd.read_csv(path + \"results.csv\")\n\nprint(\"finished retrieving stuff\")\n\n# check_patches(fd.path_finding_traj(path))\n# plot_data()\n# plot_avg_furthest_patch()\n# traj_draw(trajectories, 7, plot_patches = True)\n\n# Low density plots\nplot_selected_data(\"Average duration of visits in low densities\", 0, 3, \"duration_sum\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], divided_by= \"nb_of_visits\", mycolor = \"brown\")\nplot_selected_data(\"Average proportion of time spent in patches in low densities\", 0, 3, \"duration_sum\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], divided_by= \"total_time\", mycolor = \"brown\")\nplot_selected_data(\"Average visit rate in low densities\", 0, 3, \"nb_of_visits\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], divided_by= \"total_time\", mycolor = \"brown\")\n#plot_selected_data(\"Average number of visits in low densities\", 0, 3, \"nb_of_visits\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], mycolor = \"brown\")\n#plot_selected_data(\"Average furthest visited patch distance in low densities\", 0, 3, \"furthest_patch_distance\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], mycolor = \"brown\")\nplot_selected_data(\"Average duration of MVT visits in low densities\", 0, 3, \"duration_sum\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], divided_by= \"adjusted_nb_of_visits\", mycolor = \"brown\")\nplot_selected_data(\"Average visit rate MVT in low densities\", 0, 3, \"adjusted_nb_of_visits\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], divided_by= \"total_time\", mycolor = \"brown\")\n#plot_selected_data(\"Average proportion of visited patches in low densities\", 0, 3, \"proportion_of_visited_patches\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], mycolor = \"brown\")\n#plot_selected_data(\"Average number of visited patches in low densities\", 0, 3, \"nb_of_visited_patches\", [\"close 0.2\", \"medium 0.2\", \"far 0.2\", \"cluster 0.2\"], mycolor = \"brown\")\n\n\n# Medium density plots\nplot_selected_data(\"Average duration of visits in medium densities\", 4, 7, \"duration_sum\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], divided_by= \"nb_of_visits\", mycolor = \"orange\")\nplot_selected_data(\"Average proportion of time spent in patches in mediun densities\", 4, 7, \"duration_sum\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], divided_by= \"total_time\", mycolor = \"orange\")\nplot_selected_data(\"Average visit rate in medium densities\", 4, 7, \"nb_of_visits\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], divided_by= \"total_time\", mycolor = \"orange\")\n#plot_selected_data(\"Average number of visits in medium densities\", 4, 7, \"nb_of_visits\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], mycolor = \"orange\")\n#plot_selected_data(\"Average furthest visited patch distance in medium densities\", 4, 7, \"furthest_patch_distance\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], mycolor = \"orange\")\nplot_selected_data(\"Average duration of MVT visits in medium densities\", 4, 7, \"duration_sum\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], divided_by= \"adjusted_nb_of_visits\", mycolor = \"orange\")\nplot_selected_data(\"Average visit rate MVT in medium densities\", 4, 7, \"adjusted_nb_of_visits\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], divided_by= \"total_time\", mycolor = \"orange\")\n#plot_selected_data(\"Average proportion of visited patches in medium densities\", 4, 7, \"proportion_of_visited_patches\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], mycolor = \"orange\")\n#plot_selected_data(\"Average number of visited patches in medium densities\", 4, 7, \"nb_of_visited_patches\", [\"close 0.5\", \"medium 0.5\", \"far 0.5\", \"cluster 0.5\"], mycolor = \"orange\")\n\n\n# Full plots\n#plot_selected_data(0, 11, \"adjusted_duration_sum\", [], \"Average duration of visits\", divided_by= \"nb_of_visits\", mycolor = \"green\")\n#plot_selected_data(0, 11, \"nb_of_visited_patches\", [], \"Average proportion of visited patches\", divided_by= \"\", mycolor = \"green\")\n#plot_selected_data(0, 11, \"total_time\", [], \"Total measured time\", divided_by= \"\", mycolor = \"green\")\n#plot_selected_data(0, 11, \"duration_sum\", [], \"Average duration of visits\", divided_by= \"nb_of_visits\", mycolor = \"green\")\n\n\n# TODO marginal value theorem visits\n# TODO movement stuff between patches: speed, turning rate, MSD over time\n# TODO radial_tolerance in a useful way\n# TODO for now furthest patch is useless because should be computed depending on ORIGIN and not first recorded position\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.py b/main.py
--- a/main.py	
+++ b/main.py	
@@ -247,8 +247,8 @@
     gr.generate_and_save(path)  # run this once, will save results under path+"results.csv"
 
 # Retrieve results from what generate_and_save has saved
-trajectories = pd.read_csv(path + "trajectories.csv")
-results = pd.read_csv(path + "results.csv")
+trajectories = pd.read_csv(path + "old_trajectories.csv")
+results = pd.read_csv(path + "old_results.csv")
 
 print("finished retrieving stuff")
 
